{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"More_Plots_synth_exp_3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYns0orRXBHxaHGyKonrei"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0mKz2M4fE6I","executionInfo":{"status":"ok","timestamp":1649522972233,"user_tz":-60,"elapsed":17818,"user":{"displayName":"Χρήστος Μανιάτης","userId":"00852017530683764808"}},"outputId":"b1c1d392-5d71-406e-89ae-25312091b8e8"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Extended correlation violin plots for experiment 3 with synthetic data."],"metadata":{"id":"jru7Sc2MNb9F"}},{"cell_type":"code","metadata":{"id":"d_uLP4KIfPBU","executionInfo":{"status":"ok","timestamp":1649522975916,"user_tz":-60,"elapsed":3693,"user":{"displayName":"Χρήστος Μανιάτης","userId":"00852017530683764808"}}},"source":["from IPython import display\n","import pandas as pd\n","import numpy as np\n","import scipy\n","import scipy.stats\n","\n","from matplotlib import pyplot as plt\n","from matplotlib import colors\n","from matplotlib.ticker import PercentFormatter\n","from tensorflow import keras\n","import matplotlib.patches as mpatches\n","\n","from tensorflow.keras import layers\n","import tensorflow_probability as tfp\n","import tensorflow.compat.v2 as tf\n","tf.enable_v2_behavior()\n","\n","import pickle\n","from timeit import default_timer as timer"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"shDecIv_fPmF","executionInfo":{"status":"ok","timestamp":1649522975920,"user_tz":-60,"elapsed":17,"user":{"displayName":"Χρήστος Μανιάτης","userId":"00852017530683764808"}}},"source":["tfd = tfp.distributions\n","tfb = tfp.bijectors\n","\n","tanh = tfb.Tanh()\n","tanh_inv = tfb.Invert(tanh)\n","cor_bij = tfb.Chain([tanh,tfb.Scale(scale=0.5)])\n","cor_bij_inv = tfb.Invert(cor_bij)\n","\n","a1=[5,10,20,50,250,500] #Lower bound in coverage integrval\n","a2=[10,20,50,250,500,1000] #Upper bound in coverage interval\n","Folder = '/content/drive/MyDrive/'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nQG3YBVfSf9"},"source":["#Aggregate posterior correlations samples from different experiments.\n","lb_cor_tick=[]\n","lb_cor_scrapl_tick=[]\n","lb_cor_spr_tick=[]\n","lb_cor_prs_tick=[]\n","lb_cor = []\n","cor_scrapl_col = []\n","cor_prs_col = []\n","cor_spr_col = []\n","cor_true_col = []\n","yy=0\n","for ii in range(len(a2)):\n","\n","      with open(Folder+'SCRaPL/Synth/Data/Coverage/Beta/yy_met_'+str(a1[ii])+'_'+str(a2[ii])+'.pickle', 'rb') as handle:\n","                  yy_met= pickle.load(handle)\n","      with open(Folder+'SCRaPL/Synth/Data/Coverage/Beta/yy_cpg_'+str(a1[ii])+'_'+str(a2[ii])+'.pickle', 'rb') as handle:\n","                  yy_cpg= pickle.load(handle)   \n","      with open(Folder+'SCRaPL/Synth/Data/Coverage/Beta/yy_exp_'+str(a1[ii])+'_'+str(a2[ii])+'.pickle', 'rb') as handle:\n","                  yy_exp= pickle.load(handle)\n","      with open(Folder+'SCRaPL/Synth/Data/Coverage/Beta/Norm_'+str(a1[ii])+'_'+str(a2[ii])+'.pickle', 'rb') as handle:\n","                  norm= pickle.load(handle)   \n","\n","\n","      with open(Folder+'SCRaPL/Synth/Data/Coverage/Beta/cor_'+str(a1[ii])+'_'+str(a2[ii])+'.pickle', 'rb') as handle:\n","                  true_cor = pickle.load(handle)  \n","                  true_cor_scatter = true_cor\n","                  true_cor = cor_bij.forward(true_cor)\n","      with open(Folder+'SCRaPL/Synth/Results/Coverage/Beta/nuts_cor_'+str(a1[ii])+'_'+str(a2[ii])+'.pickle', 'rb') as handle:\n","                  nuts_cor = pickle.load(handle)\n","                  scrapl_cor_scatter = tf.reduce_mean(tf.transpose(nuts_cor) ,axis=1)[:,tf.newaxis]\n","                  nuts_cor = cor_bij.forward(tf.transpose(nuts_cor))\n","\n","      \n","      yy_met_nrm = tf.divide(yy_met,yy_cpg).numpy()\n","      yy_exp_nrm = tf.divide(yy_exp,norm).numpy()\n","      true_cor = true_cor.numpy()\n","      nuts_cor = nuts_cor.numpy()\n","      n_genes = yy_exp.shape[0]\n","\n","      drp_genes_met = np.squeeze(tf.where( tfp.stats.stddev(yy_met_nrm,sample_axis=1)==0).numpy())\n","      drp_genes_exp = np.squeeze(tf.where( tfp.stats.stddev(yy_exp_nrm,sample_axis=1)==0).numpy())\n","      drp_genes = np.union1d(drp_genes_met,drp_genes_exp)\n","      yy_met_nrm = np.delete(yy_met_nrm, drp_genes, axis=0)\n","      yy_exp_nrm = np.delete(yy_exp_nrm, drp_genes, axis=0)\n","      nuts_cor = np.delete(nuts_cor, drp_genes, axis=0)\n","      true_cor = np.delete(true_cor, drp_genes, axis=0)\n","\n","      cor_prs = np.diag(np.corrcoef(yy_met_nrm,yy_exp_nrm)[:n_genes-len(drp_genes),n_genes-len(drp_genes):] )[:,np.newaxis]\n","      cor_spr, _ = scipy.stats.spearmanr(yy_met_nrm,yy_exp_nrm,axis=1)\n","      cor_spr =  np.diag(cor_spr[:n_genes-len(drp_genes),n_genes-len(drp_genes):])[:,np.newaxis]\n","      cor_scrapl =  np.mean(nuts_cor ,axis=1)[:,np.newaxis]\n","\n","\n","      cor_scrapl_diff = cor_scrapl- true_cor\n","      ss = tfp.stats.quantiles(cor_scrapl_diff,120)\n","      cor_scrapl_diff = tf.where(tf.less_equal(cor_scrapl_diff, ss[1]), tf.zeros_like(cor_scrapl_diff), cor_scrapl_diff)\n","      cor_scrapl_diff = tf.where(tf.greater_equal(cor_scrapl_diff, ss[-2]), tf.zeros_like(cor_scrapl_diff), cor_scrapl_diff)\n","      \n","      cor_spr_diff = cor_spr - true_cor\n","      ss = tfp.stats.quantiles(cor_spr_diff,120)\n","      cor_spr_diff = tf.where(tf.less_equal(cor_spr_diff, ss[1]), tf.zeros_like(cor_spr_diff), cor_spr_diff)\n","      cor_spr_diff = tf.where(tf.greater_equal(cor_spr_diff, ss[-2]), tf.zeros_like(cor_spr_diff), cor_spr_diff)\n","\n","      cor_prs_diff = cor_prs - true_cor\n","      ss = tfp.stats.quantiles(cor_prs_diff,120)\n","      cor_prs_diff = tf.where(tf.less_equal(cor_prs_diff, ss[1]), tf.zeros_like(cor_prs_diff), cor_prs_diff)\n","      cor_prs_diff = tf.where(tf.greater_equal(cor_prs_diff, ss[-2]), tf.zeros_like(cor_prs_diff), cor_prs_diff)    \n","\n","      a=8\n","      uu = 2*ii-1+yy\n","      yy+=6\n","      lb_cor.append(str(a2[ii]))\n","      lb_cor_scrapl_tick.append(a*(uu+1-16.5/a))\n","      lb_cor_spr_tick.append(a*(uu+1))\n","      lb_cor_prs_tick.append(a*(uu+1+16.5/a))\n","\n","      cor_scrapl_col.append(cor_scrapl_diff)\n","      cor_spr_col.append(cor_spr_diff)\n","      cor_prs_col.append(cor_prs_diff)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams[\"figure.figsize\"] = (10,8)\n","plt.violinplot(cor_scrapl_col,positions=lb_cor_scrapl_tick, widths=16.5)\n","plt.xticks(lb_cor_spr_tick,lb_cor)\n","plt.violinplot(cor_spr_col,positions=lb_cor_spr_tick, widths=16.5)\n","plt.xticks(lb_cor_spr_tick,lb_cor)\n","plt.violinplot(cor_prs_col,positions=lb_cor_prs_tick, widths=16.5)\n","plt.xticks(lb_cor_spr_tick,lb_cor)\n","\n","SCRaPL_patch = mpatches.Patch(color='blue', label='SCRaPL')\n","Spearman_patch = mpatches.Patch(color='orange', label='Spearman')\n","Pearson_patch = mpatches.Patch(color='green', label='Pearson')\n","\n","plt.legend(handles=[SCRaPL_patch,Spearman_patch,Pearson_patch ],fontsize =20,loc=\"lower right\")\n","plt.hlines(y=0,xmin=-26.5,xmax=350.0,colors='r',linestyles='dashed')\n","plt.ylim(bottom=-1.0, top=1.0)\n","plt.ylabel(\"Difference from truth\",fontsize=30)\n","plt.xlabel(\"Coverage\",fontsize=30)\n","plt.savefig(Folder+'SCRaPL/Synth/Extra_Synth_violin_3.pdf', bbox_inches='tight')\n","plt.show()\n"],"metadata":{"id":"6SBBEghcO8iX"},"execution_count":null,"outputs":[]}]}