{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SCRaPL_atac_dic.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNejmJZ5LrIGmBkYKz83fIU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifDc-cTGkR6U","executionInfo":{"status":"ok","timestamp":1632071199724,"user_tz":-60,"elapsed":293,"user":{"displayName":"Χρήστος Μανιάτης","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852017530683764808"}},"outputId":"2d8fc300-de66-4253-965c-1eb4a3e2a9a9"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["This script is used to estimate DIC of SCRaPL with inflation on mEBC data. The only difference from standard inference scripts is that it stores some extra parameters like log likelihood tied to a particular sample and average of posterior latent accessibility and expression."],"metadata":{"id":"8IsRnpWJcWg1"}},{"cell_type":"code","metadata":{"id":"e6buIZRqkZT9"},"source":["from IPython import display\n","import pandas as pd\n","import numpy as np\n","import scipy\n","import scipy.stats\n","\n","from matplotlib import pyplot as plt\n","from matplotlib import colors\n","from matplotlib.ticker import PercentFormatter\n","from tensorflow import keras\n","\n","from tensorflow.keras import layers\n","import tensorflow_probability as tfp\n","import tensorflow.compat.v2 as tf\n","tf.enable_v2_behavior()\n","\n","import pickle\n","from timeit import default_timer as timer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bO5QWdjkbqt"},"source":["tfd = tfp.distributions\n","tfb = tfp.bijectors\n","Folder = '/content/drive/MyDrive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vbpaJa0Dk7qA"},"source":["#Load accessibility, expression data and cell normalization constants\n","yy_acc_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/Acc_atac.csv',',',header=[0],index_col=[0])\n","yy_exp_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/Rna_atac.csv',',',header=[0],index_col=[0])\n","Norm = pd.read_csv(Folder+'SCRaPL/Real/Data/Nrm_atac.csv',',',index_col=[1])\n","Norm = Norm.drop(columns=Norm.columns[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jbCoiv3WlmS"},"source":["yy_acc = tf.convert_to_tensor(yy_acc_pd,dtype=tf.float32)\n","yy_exp = tf.convert_to_tensor(yy_exp_pd,dtype=tf.float32)\n","Norm_acc = tf.convert_to_tensor(Norm.iloc[:,0],dtype=tf.float32)\n","Norm_exp = tf.convert_to_tensor(Norm.iloc[:,1],dtype=tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dzjJ8nmZTUj"},"source":["x_genes,x_cells = tf.shape(yy_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tF14OYMokc9U"},"source":["aff = tfb.Chain([tfb.Shift(-1.),tfb.Scale(scale=2.)])\n","aff_inv = tfb.Invert(aff)\n","\n","exp = tfb.Exp()\n","log = tfb.Invert(exp)\n","\n","tanh = tfb.Tanh()\n","tanh_inv = tfb.Invert(tanh)\n","\n","sigm = tfb.Sigmoid()\n","sigm_inv = tfb.Invert(sigm)\n","\n","cor_trsf = tfb.Chain([aff_inv,tanh,tfb.Scale(scale=0.5)])\n","cor_trsf_inv = tfb.Invert(cor_trsf)\n","\n","eps=0.001\n","bin_bij = tfb.Chain([tfb.Shift(eps/2.0),tfb.Scale(scale=1.0-eps),tfb.NormalCDF()])\n","\n","cor_bij = tfb.Chain([tanh,tfb.Scale(scale=0.5)])\n","std_bij = tfb.Chain([exp,tfb.Scale(scale=-1.0)])\n","sqr_bij = tfb.Square()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-B87ra33lOe8"},"source":["#SCRaPL's graphical model\n","def SCRaPL(N_genes,N_cells,Nrm_acc,Nrm_rna):\n","    def prior():\n","        cor_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 = 15.0*tf.ones([N_genes,1]), concentration1=15.0*tf.ones([N_genes,1])), bijector= cor_trsf_inv, name = \"cor_lt\" )\n","        m_acc_lt = yield tfd.Normal(loc=3*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_acc_lt\")\n","        m_exp_lt = yield tfd.Normal(loc=4*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_exp_lt\")\n","        s_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log, name = \"s_acc_lt\" )\n","        s_exp_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log , name = \"s_exp_lt\")\n","        infl_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_acc_lt\" )\n","        infl_rna_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_rna_lt\" )\n","\n","        cor = cor_bij.forward(cor_lt)\n","        s_acc = std_bij.forward(s_acc_lt)\n","        s_exp = std_bij.forward(s_exp_lt)\n","        infl_acc = sigm.forward(infl_acc_lt)\n","        infl_rna = sigm.forward(infl_rna_lt)\n","        \n","        mm_acc = tf.math.multiply( m_acc_lt,tf.ones([N_genes,N_cells]))\n","        mm_exp = tf.math.multiply( m_exp_lt,tf.ones([N_genes,N_cells]))\n","        ss_acc = tf.math.multiply( s_acc   ,tf.ones([N_genes,N_cells]))\n","        ss_exp = tf.math.multiply( s_exp   ,tf.ones([N_genes,N_cells]))\n","        ccor =   tf.math.multiply( cor     ,tf.ones([N_genes,N_cells]))\n","        p_acc =  tf.math.multiply( infl_acc,tf.ones([N_genes,N_cells]))\n","        p_rna =  tf.math.multiply( infl_rna,tf.ones([N_genes,N_cells]))  \n","\n","        nrm_acc = tf.math.multiply( log.forward(Nrm_acc),tf.ones([N_genes,1]))\n","        nrm_rna = tf.math.multiply( log.forward(Nrm_rna),tf.ones([N_genes,1]))\n","\n","        x_acc = yield tfd.Normal(loc = mm_acc, scale = ss_acc,name=\"x_acc\")\n","        m_cnd_exp = mm_exp+tf.math.multiply(tf.math.divide(tf.math.multiply(ss_exp,x_acc-mm_acc),ss_acc),ccor)\n","        s_cnd_exp = tf.math.sqrt(tf.math.multiply(1-tf.math.square(ccor),tf.math.square(ss_exp)))\n","\n","        x_exp = yield tfd.Normal(loc = m_cnd_exp, scale = s_cnd_exp,name=\"x_exp\")\n","\n","        pp_acc = tf.stack([p_acc,1-p_acc],axis=-1)\n","        x_acc_lt = tf.stack([-20*tf.ones_like(x_acc),x_acc+nrm_acc],axis=-1)\n","\n","        pp_rna = tf.stack([p_rna,1-p_rna],axis=-1)\n","        x_exp_lt = tf.stack([-20*tf.ones_like(x_exp),x_exp+nrm_rna],axis=-1)\n","\n","        y_acc = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_acc),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_acc_lt),\n","                                                          name=\"y_acc\")\n","        y_exp = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_rna),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_exp_lt),\n","                                                          name=\"y_exp\")\n","\n","    comp_var_coroutine = tfd.JointDistributionCoroutineAutoBatched(prior)\n","    return comp_var_coroutine\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQlypVSEebUQ"},"source":["#SCRaPL without priors used in DIC estimation.\n","def SCRaPL_dic(N_genes,N_cells,Nrm_acc,Nrm_rna,param):\n","\n","    cor_lt,m_acc_lt,m_exp_lt,s_acc_lt,s_exp_lt,infl_acc_lt,infl_rna_lt = param\n","\n","    def prior():\n","\n","        Root = tfd.JointDistributionCoroutine.Root\n","        cor = cor_bij.forward(cor_lt)\n","        s_acc = std_bij.forward(s_acc_lt)\n","        s_exp = std_bij.forward(s_exp_lt)\n","        infl_acc = sigm.forward(infl_acc_lt)\n","        infl_rna = sigm.forward(infl_rna_lt)\n","        \n","        mm_acc = tf.math.multiply( m_acc_lt,tf.ones([N_genes,N_cells]))\n","        mm_exp = tf.math.multiply( m_exp_lt,tf.ones([N_genes,N_cells]))\n","        ss_acc = tf.math.multiply( s_acc   ,tf.ones([N_genes,N_cells]))\n","        ss_exp = tf.math.multiply( s_exp   ,tf.ones([N_genes,N_cells]))\n","        ccor =   tf.math.multiply( cor     ,tf.ones([N_genes,N_cells]))\n","        p_acc =  tf.math.multiply( infl_acc,tf.ones([N_genes,N_cells]))\n","        p_rna =  tf.math.multiply( infl_rna,tf.ones([N_genes,N_cells]))  \n","\n","        nrm_acc = tf.math.multiply( log.forward(Nrm_acc),tf.ones([N_genes,1]))\n","        nrm_rna = tf.math.multiply( log.forward(Nrm_rna),tf.ones([N_genes,1]))\n","\n","        x_acc = yield Root(tfd.Independent(tfd.Normal(loc = mm_acc, scale = ss_acc,name=\"x_acc\") ,reinterpreted_batch_ndims=1))\n","        m_cnd_exp = mm_exp+tf.math.multiply(tf.math.divide(tf.math.multiply(ss_exp,x_acc-mm_acc),ss_acc),ccor)\n","        s_cnd_exp = tf.math.sqrt(tf.math.multiply(1-tf.math.square(ccor),tf.math.square(ss_exp)))\n","\n","        x_exp = yield Root(tfd.Independent(tfd.Normal(loc = m_cnd_exp, scale = s_cnd_exp,name=\"x_exp\"),reinterpreted_batch_ndims=1))\n","\n","        pp_acc = tf.stack([p_acc,1-p_acc],axis=-1)\n","        x_acc_lt = tf.stack([-20*tf.ones_like(x_acc),x_acc+nrm_acc],axis=-1)\n","\n","        pp_rna = tf.stack([p_rna,1-p_rna],axis=-1)\n","        x_exp_lt = tf.stack([-20*tf.ones_like(x_exp),x_exp+nrm_rna],axis=-1)\n","\n","        y_acc = yield Root(tfd.Independent(tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_acc),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_acc_lt),\n","                                                          name=\"y_acc\")\n","                            ,reinterpreted_batch_ndims=1))\n","\n","        y_exp = yield Root(tfd.Independent(tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_rna),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_exp_lt),\n","                                                          name=\"y_exp\")\n","                            ,reinterpreted_batch_ndims=1))\n","\n","    comp_var_coroutine = tfd.JointDistributionCoroutine(prior)\n","    return comp_var_coroutine\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMRc41S-cm7c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7515586-d00d-4c9b-fc01-4eeee6ddc7fa"},"source":["#As the dataset is too large to fit in memory we utilize genomic region independence assumption to perform sample chunks of 3 in each turn.\n","#As this step tends to be computationally demanding we halve the number of genomic regions to avoid the risk of running out of memory. Depending computational resources\n","#chunk size (www) has to be tuned \n","\n","prt = 1\n","time = []\n","skp_ind = []\n","www = 3\n","prts_tot = tf.math.ceil(x_genes/www)\n","jj = 0\n","while prt < prts_tot+1:\n","          aa =  (prt-1)*www\n","          aa1 = prt*www\n","          yy_acc_prt = yy_acc[aa:aa1,:]\n","          yy_exp_prt = yy_exp[aa:aa1,:]\n","          batch_ft = tf.shape(yy_exp_prt)[0]\n","\n","          mdl_tr = SCRaPL(batch_ft,x_cells,Norm_acc,Norm_exp)\n","          init = mdl_tr.sample()\n","          vrr = [init[0],init[1],init[2],init[3],init[4],init[5],init[6],init[7],init[8]]\n","\n","          unconstrained_bijectors = [tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity()]\n","          @tf.function(autograph=False, jit_compile=True) \n","\n","          def sample_nuts():\n","\n","                  init_x = vrr\n","                  num_burnin_iter = 3000\n","                  num_warmup_iter = int(0.8*num_burnin_iter)\n","                  num_chain_iter = 2000\n","\n","                  target_accept_rate = 0.65 \n","\n","                  log_post = lambda x0,x1,x2,x3,x4,x5,x6,x7,x8: mdl_tr.log_prob(x0,x1,x2,x3,x4,x5,x6,x7,x8,yy_acc_prt,yy_exp_prt)\n","\n","                  def trace_fn(_, pkr):\n","                        return (\n","                            pkr.inner_results.inner_results.target_log_prob,\n","                            pkr.inner_results.inner_results.leapfrogs_taken,\n","                            pkr.inner_results.inner_results.has_divergence,\n","                            pkr.inner_results.inner_results.energy,\n","                            pkr.inner_results.inner_results.log_accept_ratio,\n","                            pkr.inner_results.inner_results.step_size\n","                              )\n","                  nuts= tfp.mcmc.NoUTurnSampler(\n","                                            target_log_prob_fn=log_post,\n","                                            step_size=0.05,\n","                                            max_tree_depth=6\n","                                                ) \n","                  ttk = tfp.mcmc.TransformedTransitionKernel(\n","                                            inner_kernel=nuts,\n","                                            bijector=unconstrained_bijectors\n","                                                                )\n","                  adapted_kernel=tfp.mcmc.DualAveragingStepSizeAdaptation(\n","                                            inner_kernel=ttk,\n","                                            num_adaptation_steps=num_warmup_iter,\n","                                            target_accept_prob= target_accept_rate)\n","                  \n","                  states , sampler_stat =tfp.mcmc.sample_chain(\n","                                    num_results=num_chain_iter,\n","                                    num_burnin_steps=num_burnin_iter,\n","                                    current_state=init_x,\n","                                    kernel=adapted_kernel,\n","                                    trace_fn=trace_fn) \n","\n","                  return states, sampler_stat\n","\n","          start = timer()\n","          samples, sampler_stat = sample_nuts() \n","          end = timer()\n","          ttime = end-start\n","\n","          p_accept = tf.math.exp(tfp.math.reduce_logmeanexp(tf.minimum(sampler_stat[4], 0.)))\n","          stp_sz = sampler_stat[5][0]\n","          hmc_cor,hmc_m_acc,hmc_m_exp,hmc_s_acc,hmc_s_exp,hmc_inf_acc,hmc_inf_exp,hmc_x_acc,hmc_x_exp = samples\n","\n","          crr_nuts = tf.squeeze(hmc_cor)\n","          s_exp_nuts = tf.squeeze(hmc_s_exp)\n","          s_acc_nuts = tf.squeeze(hmc_s_acc)\n","          m_acc_nuts = tf.squeeze(hmc_m_acc)\n","          m_exp_nuts = tf.squeeze(hmc_m_exp)\n","\n","          mdl_dic = SCRaPL_dic(batch_ft,x_cells,Norm_acc,Norm_exp,[hmc_cor,hmc_m_acc,hmc_m_exp,hmc_s_acc,hmc_s_exp,hmc_inf_acc,hmc_inf_exp])\n","          llk_atac = mdl_dic.log_prob(hmc_x_acc,hmc_x_exp,yy_acc_prt,yy_exp_prt)\n","\n","          x_acc_mn = tf.reduce_mean(hmc_x_acc,axis=0)\n","          x_exp_mn = tf.reduce_mean(hmc_x_exp,axis=0)\n","\n","          qc_acc_rt = tf.math.logical_and(p_accept<0.9,p_accept>0.4)\n","          qc_stp_sz = stp_sz>0.00001\n","\n","          if tf.math.logical_and(qc_acc_rt,qc_stp_sz)== True:\n","                time.append(ttime)\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/nuts_cor_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(crr_nuts, handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/nuts_m_acc_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(m_acc_nuts, handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/nuts_m_exp_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(m_exp_nuts, handle)\n","\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/nuts_s_acc_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(s_acc_nuts, handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/nuts_s_exp_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(s_exp_nuts, handle)\n","\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/nuts_inf_acc_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(tf.squeeze(hmc_inf_acc), handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/nuts_inf_exp_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(tf.squeeze(hmc_inf_exp), handle)\n","                    \n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/avg_exp_inf_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(x_exp_mn, handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/avg_met_inf_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(x_acc_mn, handle)   \n","\n","                with open(Folder+'SCRaPL/Real/Results_atac_DIC/log_prob_atac_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(llk_atac, handle)\n","\n","                avg_time = tf.reduce_mean(tf.stack(time))\n","                rem_time = (tf.cast(prts_tot,dtype=tf.float32)-tf.cast(prt,dtype=tf.float32)) *avg_time\n","                print(tf.squeeze([rem_time,prt,stp_sz,p_accept]),tf.math.logical_and(qc_acc_rt,qc_stp_sz))\n","                prt+=1\n","                jj = 0.0\n","          else:\n","                time.append(ttime)\n","                \n","                if jj>3.0:\n","                    skp_ind.append(prt)\n","                    prt+=1\n","                    jj=0.0\n","\n","                avg_time = tf.reduce_mean(tf.stack(time))\n","                rem_time = (tf.cast(prts_tot,dtype=tf.float32)-tf.cast(prt,dtype=tf.float32)) *avg_time\n","                print(tf.squeeze([rem_time,prt,stp_sz,p_accept]),tf.math.logical_and(qc_acc_rt,qc_stp_sz))\n","                jj+=1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([1.4797806e+04 1.3320000e+03 1.0986957e-02 6.8224877e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.4861635e+04 1.3330000e+03 1.0315918e-02 6.6909182e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.45823193e+04 1.33400000e+03 1.00535955e-02 6.69788003e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.4446388e+04 1.3350000e+03 1.1083351e-02 6.6893226e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","WARNING:tensorflow:5 out of the last 5 calls to <function sample_nuts at 0x7fe88c1cb200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","tf.Tensor([1.4227613e+04 1.3360000e+03 1.0599324e-02 6.7635357e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","WARNING:tensorflow:6 out of the last 6 calls to <function sample_nuts at 0x7fe90a6987a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","tf.Tensor([1.4046469e+04 1.3370000e+03 1.0321848e-02 7.2689098e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.3898899e+04 1.3380000e+03 1.1638055e-02 6.8417579e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.37147559e+04 1.33900000e+03 1.12648215e-02 6.60554826e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.3527330e+04 1.3400000e+03 1.0633833e-02 6.5752316e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.3344652e+04 1.3410000e+03 1.0360379e-02 6.5269256e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.316380e+04 1.342000e+03 9.675593e-03 7.155295e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.3020871e+04 1.3430000e+03 1.0358210e-02 6.0342348e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.2845035e+04 1.3440000e+03 1.1270393e-02 6.6154265e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.2667669e+04 1.3450000e+03 1.1871851e-02 6.3810366e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.2497952e+04 1.3460000e+03 9.5764948e-03 7.1075106e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.2332024e+04 1.3470000e+03 1.0779984e-02 6.5503472e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.2149724e+04 1.3480000e+03 1.1080978e-02 6.6233236e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.1981626e+04 1.3490000e+03 1.0831537e-02 6.6128182e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.1803267e+04 1.3500000e+03 1.0578717e-02 6.9154155e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.16208184e+04 1.35100000e+03 1.11787515e-02 6.52672946e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.1438838e+04 1.3520000e+03 1.1231695e-02 6.6301548e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.1262010e+04 1.3530000e+03 1.1886715e-02 6.4960223e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.1083614e+04 1.3540000e+03 1.0807448e-02 7.0777792e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.0919887e+04 1.3550000e+03 1.1261545e-02 6.5307111e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.0738867e+04 1.3560000e+03 1.0852971e-02 6.7185599e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.0558940e+04 1.3570000e+03 1.1437907e-02 6.3891053e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.0383788e+04 1.3580000e+03 1.0871777e-02 6.9320810e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.0205559e+04 1.3590000e+03 1.0886667e-02 6.7669517e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([1.00260527e+04 1.36000000e+03 1.06060775e-02 7.09112942e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([9.8487344e+03 1.3610000e+03 1.2185259e-02 6.5297616e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([9.6707832e+03 1.3620000e+03 1.1556251e-02 6.8095487e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([9.4933076e+03 1.3630000e+03 1.0389711e-02 7.0917755e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([9.320173e+03 1.364000e+03 9.750791e-03 7.168716e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([9.1439990e+03 1.3650000e+03 1.0378599e-02 6.6544449e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([8.966657e+03 1.366000e+03 9.762408e-03 6.713135e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([8.7904014e+03 1.3670000e+03 1.1575873e-02 6.7929280e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([8.6128008e+03 1.3680000e+03 1.0828402e-02 6.9378912e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([8.4346709e+03 1.3690000e+03 1.0750105e-02 6.8436438e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([8.25760938e+03 1.37000000e+03 1.07664745e-02 6.52691901e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([8.0807280e+03 1.3710000e+03 1.0699278e-02 6.5580070e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([7.9036929e+03 1.3720000e+03 1.0954858e-02 7.1459556e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([7.7275664e+03 1.3730000e+03 1.0839292e-02 6.3594669e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([7.550488e+03 1.374000e+03 1.070968e-02 6.742354e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([7.3734873e+03 1.3750000e+03 1.2411226e-02 6.5627271e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([7.1970010e+03 1.3760000e+03 1.0703094e-02 6.8839198e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([7.0217842e+03 1.3770000e+03 1.1752472e-02 6.8001515e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([6.8465747e+03 1.3780000e+03 1.1484141e-02 6.6387254e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([6.6690674e+03 1.3790000e+03 1.1531567e-02 6.5817314e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([6.4955718e+03 1.3800000e+03 1.1180628e-02 6.8801099e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([6.3204995e+03 1.3810000e+03 1.0889184e-02 6.6369969e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([6.1465366e+03 1.3820000e+03 1.1097657e-02 6.5573907e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([5.9701348e+03 1.3830000e+03 1.0785919e-02 6.6495067e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","tf.Tensor([5.7944795e+03 1.3840000e+03 1.1314282e-02 6.8736041e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n"]}]}]}