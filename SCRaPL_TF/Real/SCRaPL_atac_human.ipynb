{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SCRaPL_atac_human.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNR0xJY9OP5IbhJikmhPI9P"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifDc-cTGkR6U","executionInfo":{"status":"ok","timestamp":1634534660991,"user_tz":-60,"elapsed":380,"user":{"displayName":"Χρήστος Μανιάτης","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852017530683764808"}},"outputId":"96f58da4-69c5-4337-ac98-aec86b5cc266"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["This script was added after the first round of feedback where we were asked to compare SCRaPL to Seurat. This script is used to estimate SCRaPL parameters. It is an essential part of preprocessing."],"metadata":{"id":"UDPgNg3wgNRT"}},{"cell_type":"code","metadata":{"id":"e6buIZRqkZT9"},"source":["from IPython import display\n","import pandas as pd\n","import numpy as np\n","import scipy\n","import scipy.stats\n","\n","from matplotlib import pyplot as plt\n","from matplotlib import colors\n","from matplotlib.ticker import PercentFormatter\n","from tensorflow import keras\n","\n","from tensorflow.keras import layers\n","import tensorflow_probability as tfp\n","import tensorflow.compat.v2 as tf\n","tf.enable_v2_behavior()\n","\n","import pickle\n","from timeit import default_timer as timer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bO5QWdjkbqt"},"source":["tfd = tfp.distributions\n","tfb = tfp.bijectors\n","Folder = '/content/drive/MyDrive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vbpaJa0Dk7qA"},"source":["#Load accessibility, expression negative control data and cell normalization constants\n","yy_acc_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/human_acc_tmp_1.csv',',',header=[0])\n","yy_exp_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/human_rna_tmp_1.csv',',',header=[0])\n","\n","Norm_acc_pd = pd.read_csv(Folder+'SCRaPL_fin/Real/Data/nrm_human_acc_tmp.csv',',',header=[0],index_col=[0])\n","Norm_exp_pd = pd.read_csv(Folder+'SCRaPL_fin/Real/Data/nrm_human_rna_tmp.csv',',',header=[0],index_col=[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jbCoiv3WlmS"},"source":["yy_acc = tf.convert_to_tensor(yy_acc_pd,dtype=tf.float32)\n","yy_exp = tf.convert_to_tensor(yy_exp_pd,dtype=tf.float32)\n","Norm_acc = tf.transpose(tf.convert_to_tensor(Norm_acc_pd,dtype=tf.float32))\n","Norm_exp = tf.transpose(tf.convert_to_tensor(Norm_exp_pd,dtype=tf.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dzjJ8nmZTUj"},"source":["x_genes,x_cells = tf.shape(yy_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tF14OYMokc9U"},"source":["aff = tfb.Chain([tfb.Shift(-1.),tfb.Scale(scale=2.)])\n","aff_inv = tfb.Invert(aff)\n","\n","exp = tfb.Exp()\n","log = tfb.Invert(exp)\n","\n","tanh = tfb.Tanh()\n","tanh_inv = tfb.Invert(tanh)\n","\n","sigm = tfb.Sigmoid()\n","sigm_inv = tfb.Invert(sigm)\n","\n","cor_trsf = tfb.Chain([aff_inv,tanh,tfb.Scale(scale=0.5)])\n","cor_trsf_inv = tfb.Invert(cor_trsf)\n","\n","eps=0.001\n","bin_bij = tfb.Chain([tfb.Shift(eps/2.0),tfb.Scale(scale=1.0-eps),tfb.NormalCDF()])\n","\n","cor_bij = tfb.Chain([tanh,tfb.Scale(scale=0.5)])\n","std_bij = tfb.Chain([exp,tfb.Scale(scale=-1.0)])\n","sqr_bij = tfb.Square()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-B87ra33lOe8"},"source":["#SCRaPL's graphical model\n","def SCRaPL(N_genes,N_cells,Nrm_acc,Nrm_rna):\n","    def prior():\n","        cor_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 = 15.0*tf.ones([N_genes,1]), concentration1=15.0*tf.ones([N_genes,1])), bijector= cor_trsf_inv, name = \"cor_lt\" )\n","        m_acc_lt = yield tfd.Normal(loc=3*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_acc_lt\")\n","        m_exp_lt = yield tfd.Normal(loc=4*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_exp_lt\")\n","        s_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log, name = \"s_acc_lt\" )\n","        s_exp_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log , name = \"s_exp_lt\")\n","        infl_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_acc_lt\" )\n","        infl_rna_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_rna_lt\" )\n","\n","        cor = cor_bij.forward(cor_lt)\n","        s_acc = std_bij.forward(s_acc_lt)\n","        s_exp = std_bij.forward(s_exp_lt)\n","        infl_acc = sigm.forward(infl_acc_lt)\n","        infl_rna = sigm.forward(infl_rna_lt)\n","        \n","        mm_acc = tf.math.multiply( m_acc_lt,tf.ones([N_genes,N_cells]))\n","        mm_exp = tf.math.multiply( m_exp_lt,tf.ones([N_genes,N_cells]))\n","        ss_acc = tf.math.multiply( s_acc   ,tf.ones([N_genes,N_cells]))\n","        ss_exp = tf.math.multiply( s_exp   ,tf.ones([N_genes,N_cells]))\n","        ccor =   tf.math.multiply( cor     ,tf.ones([N_genes,N_cells]))\n","        p_acc =  tf.math.multiply( infl_acc,tf.ones([N_genes,N_cells]))\n","        p_rna =  tf.math.multiply( infl_rna,tf.ones([N_genes,N_cells]))  \n","\n","        nrm_acc = tf.math.multiply( log.forward(Nrm_acc),tf.ones([N_genes,1]))\n","        nrm_rna = tf.math.multiply( log.forward(Nrm_rna),tf.ones([N_genes,1]))\n","\n","        x_acc = yield tfd.Normal(loc = mm_acc, scale = ss_acc,name=\"x_acc\")\n","        m_cnd_exp = mm_exp+tf.math.multiply(tf.math.divide(tf.math.multiply(ss_exp,x_acc-mm_acc),ss_acc),ccor)\n","        s_cnd_exp = tf.math.sqrt(tf.math.multiply(1-tf.math.square(ccor),tf.math.square(ss_exp)))\n","\n","        x_exp = yield tfd.Normal(loc = m_cnd_exp, scale = s_cnd_exp,name=\"x_exp\")\n","\n","        pp_acc = tf.stack([p_acc,1-p_acc],axis=-1)\n","        x_acc_lt = tf.stack([-20*tf.ones_like(x_acc),x_acc+nrm_acc],axis=-1)\n","\n","        pp_rna = tf.stack([p_rna,1-p_rna],axis=-1)\n","        x_exp_lt = tf.stack([-20*tf.ones_like(x_exp),x_exp+nrm_rna],axis=-1)\n","\n","        y_acc = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_acc),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_acc_lt),\n","                                                          name=\"y_acc\")\n","        y_exp = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_rna),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_exp_lt),\n","                                                          name=\"y_exp\")\n","\n","    comp_var_coroutine = tfd.JointDistributionCoroutineAutoBatched(prior)\n","    return comp_var_coroutine\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMRc41S-cm7c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1aa44ac2-d624-4eb9-ff9d-77c53ff80330"},"source":["#As the dataset is too large to fit in memory we utilize genomic region independence assumption to perform sample chunks of 60 in each turn.\n","#This also makes it easier to tune parameters to target acceptance rate as the sampling space is reduced. Depending computational resources\n","#chunk size (www) has to be tuned \n","\n","prt = 1\n","time = []\n","skp_ind = []\n","www = 60\n","prts_tot = tf.math.ceil(x_genes/www)\n","jj = 0\n","while prt < prts_tot+1:\n","          aa =  (prt-1)*www\n","          aa1 = prt*www\n","          yy_acc_prt = yy_acc[aa:aa1,:]\n","          yy_exp_prt = yy_exp[aa:aa1,:]\n","\n","          batch_ft = tf.shape(yy_exp_prt)[0]\n","\n","          mdl_tr = SCRaPL(batch_ft,x_cells,Norm_acc,Norm_exp)\n","          init = mdl_tr.sample()\n","          vrr = [init[0],init[1],init[2],init[3],init[4],init[5],init[6],init[7],init[8]]\n","\n","          unconstrained_bijectors = [tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity()]\n","          @tf.function(autograph=False, jit_compile=True) \n","\n","          def sample_nuts():\n","\n","                  init_x = vrr\n","                  num_burnin_iter = 3000\n","                  num_warmup_iter = int(0.8*num_burnin_iter)\n","                  num_chain_iter = 2000\n","\n","                  target_accept_rate = 0.65 \n","\n","                  log_post = lambda x0,x1,x2,x3,x4,x5,x6,x7,x8: mdl_tr.log_prob(x0,x1,x2,x3,x4,x5,x6,x7,x8,yy_acc_prt,yy_exp_prt)\n","\n","                  def trace_fn(_, pkr):\n","                        return (\n","                            pkr.inner_results.inner_results.target_log_prob,\n","                            pkr.inner_results.inner_results.leapfrogs_taken,\n","                            pkr.inner_results.inner_results.has_divergence,\n","                            pkr.inner_results.inner_results.energy,\n","                            pkr.inner_results.inner_results.log_accept_ratio,\n","                            pkr.inner_results.inner_results.step_size\n","                              )\n","                  nuts= tfp.mcmc.NoUTurnSampler(\n","                                            target_log_prob_fn=log_post,\n","                                            step_size=0.05,\n","                                            max_tree_depth=6\n","                                                ) \n","                  ttk = tfp.mcmc.TransformedTransitionKernel(\n","                                            inner_kernel=nuts,\n","                                            bijector=unconstrained_bijectors\n","                                                                )\n","                  adapted_kernel=tfp.mcmc.DualAveragingStepSizeAdaptation(\n","                                            inner_kernel=ttk,\n","                                            num_adaptation_steps=num_warmup_iter,\n","                                            target_accept_prob= target_accept_rate)\n","                  \n","                  states , sampler_stat =tfp.mcmc.sample_chain(\n","                                    num_results=num_chain_iter,\n","                                    num_burnin_steps=num_burnin_iter,\n","                                    current_state=init_x,\n","                                    kernel=adapted_kernel,\n","                                    trace_fn=trace_fn) \n","\n","                  return states, sampler_stat\n","\n","          start = timer()\n","          samples, sampler_stat = sample_nuts() \n","          end = timer()\n","          ttime = end-start\n","\n","          p_accept = tf.math.exp(tfp.math.reduce_logmeanexp(tf.minimum(sampler_stat[4], 0.)))\n","          \n","          stp_sz = sampler_stat[5][0]\n","          hmc_cor,hmc_m_acc,hmc_m_exp,hmc_s_acc,hmc_s_exp,hmc_inf_acc,hmc_inf_exp,hmc_x_acc,hmc_x_exp = samples\n","\n","          crr_nuts = tf.squeeze(hmc_cor)\n","          s_exp_nuts = tf.squeeze(hmc_s_exp)\n","          s_acc_nuts = tf.squeeze(hmc_s_acc)\n","          m_acc_nuts = tf.squeeze(hmc_m_acc)\n","          m_exp_nuts = tf.squeeze(hmc_m_exp)\n","\n","          qc_acc_rt = p_accept> tf.math.logical_and(p_accept<0.9,p_accept>0.4)\n","          qc_stp_sz = stp_sz>0.00001\n","\n","          if tf.math.logical_and(qc_acc_rt,qc_stp_sz)== True:\n","                time.append(ttime)\n","                with open(Folder+'SCRaPL/Real/Results_atac_human/nuts_cor_atac_tmp_1_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(crr_nuts, handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_human/nuts_m_acc_atac_tmp_1_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(m_acc_nuts, handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_human/nuts_m_exp_atac_tmp_1_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(m_exp_nuts, handle)\n","                \n","                with open(Folder+'SCRaPL/Real/Results_atac_human/nuts_s_acc_atac_tmp_1_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(s_acc_nuts, handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_human/nuts_s_exp_atac_tmp_1_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(s_exp_nuts, handle)\n","\n","                with open(Folder+'SCRaPL/Real/Results_atac_human/nuts_inf_acc_atac_tmp_1_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(tf.squeeze(hmc_inf_acc), handle)\n","                with open(Folder+'SCRaPL/Real/Results_atac_human/nuts_inf_exp_atac_tmp_1_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(tf.squeeze(hmc_inf_exp), handle)\n","                    \n","                with open(Folder+'SCRaPL/Synth/Results/'+ref+'/nuts_x_met_'+ref+'_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(tf.squeeze(hmc_x_met), handle)\n","                with open(Folder+'SCRaPL/Synth/Results/'+ref+'/nuts_x_exp_'+ref+'_'+str(prt)+'.pickle', 'wb') as handle:\n","                    pickle.dump(tf.squeeze(hmc_x_exp), handle)\n","                \n","                avg_time = tf.reduce_mean(tf.stack(time))\n","                rem_time = (tf.cast(prts_tot,dtype=tf.float32)-tf.cast(prt,dtype=tf.float32)) *avg_time\n","                print(tf.squeeze([rem_time,prt,stp_sz,p_accept]),tf.math.logical_and(qc_acc_rt,qc_stp_sz))\n","                prt+=1\n","                jj=0.0\n","          else:\n","                time.append(ttime)\n","                \n","                if jj>3.0:\n","                    skp_ind.append(prt)\n","                    prt+=1\n","                    jj=0.0\n","\n","                avg_time = tf.reduce_mean(tf.stack(time))\n","                rem_time = (tf.cast(prts_tot,dtype=tf.float32)-tf.cast(prt,dtype=tf.float32)) *avg_time\n","                print(tf.squeeze([rem_time,prt,stp_sz,p_accept]),tf.math.logical_and(qc_acc_rt,qc_stp_sz))\n","                jj+=1\n","     "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","tf.Tensor([3.2365097e+05 8.6000000e+01 7.2555216e-03 4.2829347e-01], shape=(4,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"]}]}]}