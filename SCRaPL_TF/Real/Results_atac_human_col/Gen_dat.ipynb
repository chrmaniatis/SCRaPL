{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gen_dat.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMdJfiK0s0vTtr33/q/ixun"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifDc-cTGkR6U","executionInfo":{"status":"ok","timestamp":1634570574967,"user_tz":-60,"elapsed":301,"user":{"displayName":"Χρήστος Μανιάτης","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852017530683764808"}},"outputId":"210d2934-38bc-41e6-ca27-19d97941efcd"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["After inference we use SCRaPL's generative model to sample latnet expression and accessibility space. In turn this data are used in Seurat's integration pipeline."],"metadata":{"id":"LhWu1k2VSF33"}},{"cell_type":"code","metadata":{"id":"e6buIZRqkZT9"},"source":["from IPython import display\n","import pandas as pd\n","import numpy as np\n","import scipy\n","import scipy.stats\n","\n","from matplotlib import pyplot as plt\n","from matplotlib import colors\n","from matplotlib.ticker import PercentFormatter\n","from tensorflow import keras\n","\n","from tensorflow.keras import layers\n","import tensorflow_probability as tfp\n","import tensorflow.compat.v2 as tf\n","tf.enable_v2_behavior()\n","\n","import pickle\n","from timeit import default_timer as timer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kn3c75K8rZLW"},"source":["tfd = tfp.distributions\n","tfb = tfp.bijectors\n","Folder = '/content/drive/MyDrive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58ijk-1rjsTy"},"source":["#Load samples for latent parameters.\n","with open(Folder+'SCRaPL/Real/Results_atac_human_col/nuts_cor_atac_tmp_1.pickle', 'rb') as handle:\n","    cor_nuts = pickle.load(handle)\n","with open(Folder+'SCRaPL/Real/Results_atac_human_col/nuts_m_acc_atac_tmp_1.pickle', 'rb') as handle:\n","    m_acc_nuts = pickle.load(handle)\n","with open(Folder+'SCRaPL/Real/Results_atac_human_col/nuts_m_exp_atac_tmp_1.pickle', 'rb') as handle:\n","    m_exp_nuts = pickle.load(handle)\n","with open(Folder+'SCRaPL/Real/Results_atac_human_col/nuts_s_acc_atac_tmp_1.pickle', 'rb') as handle:\n","    s_acc_nuts = pickle.load(handle)\n","with open(Folder+'SCRaPL/Real/Results_atac_human_col/nuts_s_exp_atac_tmp_1.pickle', 'rb') as handle:\n","    s_exp_nuts = pickle.load(handle)\n","with open(Folder+'SCRaPL/Real/Results_atac_human_col/nuts_inf_exp_atac_tmp_1.pickle', 'rb') as handle:\n","    inf_exp_nuts = pickle.load(handle)\n","with open(Folder+'SCRaPL/Real/Results_atac_human_col/nuts_inf_acc_atac_tmp_1.pickle', 'rb') as handle:\n","    inf_acc_nuts = pickle.load(handle)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QdsAepCenGUy"},"source":["#Load raw expression and accessibility data and normalization constants.\n","yy_acc_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/human_acc_tmp_1.csv',',',header=[0])\n","yy_exp_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/human_rna_tmp_1.csv',',',header=[0])\n","\n","Norm_acc_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/nrm_human_acc_tmp.csv',',',header=[0],index_col=[0])\n","Norm_exp_pd = pd.read_csv(Folder+'SCRaPL/Real/Data/nrm_human_rna_tmp.csv',',',header=[0],index_col=[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7O6mHErt5jS"},"source":["yy_acc = tf.convert_to_tensor(yy_acc_pd,dtype=tf.float32)\n","yy_exp = tf.convert_to_tensor(yy_exp_pd,dtype=tf.float32)\n","Norm_acc = tf.transpose(tf.convert_to_tensor(Norm_acc_pd,dtype=tf.float32))\n","Norm_exp = tf.transpose(tf.convert_to_tensor(Norm_exp_pd,dtype=tf.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmnJcP7KrhSj"},"source":["aff = tfb.Chain([tfb.Shift(-1.),tfb.Scale(scale=2.)])\n","aff_inv = tfb.Invert(aff)\n","\n","exp = tfb.Exp()\n","log = tfb.Invert(exp)\n","\n","tanh = tfb.Tanh()\n","tanh_inv = tfb.Invert(tanh)\n","\n","sigm = tfb.Sigmoid()\n","sigm_inv = tfb.Invert(sigm)\n","\n","cor_trsf = tfb.Chain([aff_inv,tanh,tfb.Scale(scale=0.5)])\n","cor_trsf_inv = tfb.Invert(cor_trsf)\n","\n","eps=0.001\n","bin_bij = tfb.Chain([tfb.Shift(eps/2.0),tfb.Scale(scale=1.0-eps),tfb.NormalCDF()])\n","\n","cor_bij = tfb.Chain([tanh,tfb.Scale(scale=0.5)])\n","std_bij = tfb.Chain([exp,tfb.Scale(scale=-1.0)])\n","sqr_bij = tfb.Square()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJKjVTwJnA-Y"},"source":["#SCRaPL's generative model\n","def SCRaPL(N_genes,N_cells,Nrm_acc,Nrm_rna):\n","    def prior():\n","        cor_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 = 15.0*tf.ones([N_genes,1]), concentration1=15.0*tf.ones([N_genes,1])), bijector= cor_trsf_inv, name = \"cor_lt\" )\n","        m_acc_lt = yield tfd.Normal(loc=3*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_acc_lt\")\n","        m_exp_lt = yield tfd.Normal(loc=4*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_exp_lt\")\n","        s_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log, name = \"s_acc_lt\" )\n","        s_exp_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log , name = \"s_exp_lt\")\n","        infl_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_acc_lt\" )\n","        infl_rna_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_rna_lt\" )\n","\n","        cor = cor_bij.forward(cor_lt)\n","        s_acc = std_bij.forward(s_acc_lt)\n","        s_exp = std_bij.forward(s_exp_lt)\n","        infl_acc = sigm.forward(infl_acc_lt)\n","        infl_rna = sigm.forward(infl_rna_lt)\n","        \n","        mm_acc = tf.math.multiply( m_acc_lt,tf.ones([N_genes,N_cells]))\n","        mm_exp = tf.math.multiply( m_exp_lt,tf.ones([N_genes,N_cells]))\n","        ss_acc = tf.math.multiply( s_acc   ,tf.ones([N_genes,N_cells]))\n","        ss_exp = tf.math.multiply( s_exp   ,tf.ones([N_genes,N_cells]))\n","        ccor =   tf.math.multiply( cor     ,tf.ones([N_genes,N_cells]))\n","        p_acc =  tf.math.multiply( infl_acc,tf.ones([N_genes,N_cells]))\n","        p_rna =  tf.math.multiply( infl_rna,tf.ones([N_genes,N_cells]))  \n","\n","        nrm_acc = tf.math.multiply( log.forward(Nrm_acc),tf.ones([N_genes,1]))\n","        nrm_rna = tf.math.multiply( log.forward(Nrm_rna),tf.ones([N_genes,1]))\n","\n","        x_acc = yield tfd.Normal(loc = mm_acc, scale = ss_acc,name=\"x_acc\")\n","        m_cnd_exp = mm_exp+tf.math.multiply(tf.math.divide(tf.math.multiply(ss_exp,x_acc-mm_acc),ss_acc),ccor)\n","        s_cnd_exp = tf.math.sqrt(tf.math.multiply(1-tf.math.square(ccor),tf.math.square(ss_exp)))\n","\n","        x_exp = yield tfd.Normal(loc = m_cnd_exp, scale = s_cnd_exp,name=\"x_exp\")\n","\n","        pp_acc = tf.stack([p_acc,1-p_acc],axis=-1)\n","        x_acc_lt = tf.stack([-20*tf.ones_like(x_acc),x_acc+nrm_acc],axis=-1)\n","\n","        pp_rna = tf.stack([p_rna,1-p_rna],axis=-1)\n","        x_exp_lt = tf.stack([-20*tf.ones_like(x_exp),x_exp+nrm_rna],axis=-1)\n","\n","        y_acc = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_acc),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_acc_lt),\n","                                                          name=\"y_acc\")\n","        y_exp = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_rna),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_exp_lt),\n","                                                          name=\"y_exp\")\n","\n","    comp_var_coroutine = tfd.JointDistributionCoroutineAutoBatched(prior)\n","    return comp_var_coroutine"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AyzCIqaxn9j5"},"source":["x_genes = tf.shape(yy_acc)[0]\n","x_cells = tf.shape(yy_acc)[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQmtK1mloPtG"},"source":["cor_mn = tf.reduce_mean(cor_nuts,axis=0)[:,tf.newaxis]\n","m_acc_mn = tf.reduce_mean(m_acc_nuts,axis=0)[:,tf.newaxis]\n","m_exp_mn = tf.reduce_mean(m_exp_nuts,axis=0)[:,tf.newaxis]\n","s_acc_mn = tf.reduce_mean(s_acc_nuts,axis=0)[:,tf.newaxis]\n","s_exp_mn = tf.reduce_mean(s_exp_nuts,axis=0)[:,tf.newaxis]\n","inf_acc_mn = tf.reduce_mean(inf_acc_nuts,axis=0)[:,tf.newaxis]\n","inf_exp_mn = tf.reduce_mean(inf_exp_nuts,axis=0)[:,tf.newaxis]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#As the dataset consists of 60000 peaks and 3000 cells there is not enough memory to generate latent state parameters. For that reason we break the data into 3 chunks.\n","prt = 3 \n","aaa = 20000*(prt) + 1 \n","aaa1 = 20000*(prt-1) \n","cor_mn_1 = cor_mn[aaa1:aaa]\n","m_acc_mn_1 = m_acc_mn[aaa1:aaa]\n","m_exp_mn_1 = m_exp_mn[aaa1:aaa]\n","s_acc_mn_1 = s_acc_mn[aaa1:aaa]\n","s_exp_mn_1 = s_exp_mn[aaa1:aaa]\n","inf_acc_mn_1 = inf_acc_mn[aaa1:aaa]\n","inf_exp_mn_1 = inf_exp_mn[aaa1:aaa]"],"metadata":{"id":"8ev6frvwOuhb"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"56s_QfHCzoig"},"source":["mdl = SCRaPL(tf.cast(aaa-aaa1,dtype=tf.int64),x_cells,Norm_acc,Norm_exp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7yxdUaf0ebv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634570789818,"user_tz":-60,"elapsed":45581,"user":{"displayName":"Χρήστος Μανιάτης","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00852017530683764808"}},"outputId":"3b26b6ce-1465-4751-935a-45400e71a10b"},"source":["#Sample latent space parameters\n","_,_,_,_,_,_,_,xx_acc,xx_exp,yyy_acc,yyy_exp = mdl.sample(value=(cor_mn_1,m_acc_mn_1,m_exp_mn_1,s_acc_mn_1,s_exp_mn_1,inf_acc_mn_1,inf_exp_mn_1,None,None,None,None)) "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"]}]},{"cell_type":"code","metadata":{"id":"f_stfC4R4cmk"},"source":["#Save latent space parameters\n","s1 = pd.DataFrame(tf.squeeze(tf.exp(xx_acc)).numpy(), columns= yy_acc_pd.columns, index = yy_acc_pd.index[aaa1:aaa])\n","s2 = pd.DataFrame(tf.squeeze(tf.exp(xx_exp)).numpy(), columns= yy_exp_pd.columns, index = yy_exp_pd.index[aaa1:aaa])\n","\n","s1.to_csv(Folder+'SCRaPL/Real/Results_atac_human_col/Seurat_int_acc_tmp_1_'+str(prt)+\".csv\", sep =\",\")\n","s2.to_csv(Folder+'SCRaPL/Real/Results_atac_human_col/Seurat_int_exp_tmp_1_'+str(prt)+\".csv\", sep =\",\")"],"execution_count":null,"outputs":[]}]}