{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Demo_10X_large_data.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOv5+AQWhy7N3bp8Haq0Cs/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifDc-cTGkR6U","executionInfo":{"status":"ok","timestamp":1649171113543,"user_tz":-60,"elapsed":2510,"user":{"displayName":"Χρήστος Μανιάτης","userId":"00852017530683764808"}},"outputId":"d9bf4b57-948d-44ef-ebe7-3313b32db7bf"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Demo for 10X large data. In large datasets (ie >= 100k SCRaPL parameters) is common to run out of memory or observe ineffective space exploration. NUTS parameters are tunned to achieve prespecified acceptance probability. In high dimensions this might translate to tiny step sizes, making the state exploration ineffective. To overcome that, we exploit the feature independence to reduce the dimensionality of the problem. More precisely, we infer posterior in batches (without replacement)."],"metadata":{"id":"ZS-a1lKGBWHJ"}},{"cell_type":"code","metadata":{"id":"e6buIZRqkZT9"},"source":["from IPython import display\n","import pandas as pd\n","import numpy as np\n","import scipy\n","import scipy.stats\n","\n","from matplotlib import pyplot as plt\n","from matplotlib import colors\n","from matplotlib.ticker import PercentFormatter\n","from tensorflow import keras\n","\n","from tensorflow.keras import layers\n","import tensorflow_probability as tfp\n","import tensorflow.compat.v2 as tf\n","tf.enable_v2_behavior()\n","\n","import pickle\n","from timeit import default_timer as timer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bO5QWdjkbqt"},"source":["tfd = tfp.distributions\n","tfb = tfp.bijectors\n","Folder = '/content/drive/MyDrive/SCRaPL/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SkbWIaztHrtL"},"source":["a1 = 1000 #Number of genes\n","a2 = 800 #Number of cells\n","prts = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tF14OYMokc9U"},"source":["#Define bijectors variables transformation to sample in an unbounded support.\n","aff = tfb.Chain([tfb.Shift(-1.),tfb.Scale(scale=2.)])\n","aff_inv = tfb.Invert(aff)\n","\n","exp = tfb.Exp()\n","log = tfb.Invert(exp)\n","\n","tanh = tfb.Tanh()\n","tanh_inv = tfb.Invert(tanh)\n","\n","sigm = tfb.Sigmoid()\n","sigm_inv = tfb.Invert(sigm)\n","\n","cor_trsf = tfb.Chain([aff_inv,tanh,tfb.Scale(scale=0.5)])\n","cor_trsf_inv = tfb.Invert(cor_trsf)\n","\n","eps=0.001\n","bin_bij = tfb.Chain([tfb.Shift(eps/2.0),tfb.Scale(scale=1.0-eps),tfb.NormalCDF()])\n","\n","cor_bij = tfb.Chain([tanh,tfb.Scale(scale=0.5)])\n","std_bij = tfb.Chain([exp,tfb.Scale(scale=-1.0)])\n","sqr_bij = tfb.Square()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Define SCRaPL's graphical model.\n","\n","def SCRaPL(N_genes,N_cells,Nrm_acc,Nrm_rna):\n","    def model():\n","        cor_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 = 15.0*tf.ones([N_genes,1]), concentration1=15.0*tf.ones([N_genes,1])), bijector= cor_trsf_inv, name = \"cor_lt\" )\n","        m_acc_lt = yield tfd.Normal(loc=3*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_acc_lt\")\n","        m_exp_lt = yield tfd.Normal(loc=4*tf.ones([N_genes,1]),scale=tf.ones([N_genes,1]), name = \"m_exp_lt\")\n","        s_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log, name = \"s_acc_lt\" )\n","        s_exp_lt = yield tfd.TransformedDistribution( distribution = tfd.InverseGamma(concentration=2.5*tf.ones([N_genes,1]),scale=4.5*tf.ones([N_genes,1])),bijector= log , name = \"s_exp_lt\")\n","        infl_acc_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_acc_lt\" )\n","        infl_rna_lt = yield tfd.TransformedDistribution( distribution = tfd.Beta( concentration0 =8.0*tf.ones([N_genes,1]), concentration1=2.0*tf.ones([N_genes,1])), bijector= sigm_inv, name = \"infl_rna_lt\" )\n","\n","        cor = cor_bij.forward(cor_lt)\n","        s_acc = std_bij.forward(s_acc_lt)\n","        s_exp = std_bij.forward(s_exp_lt)\n","        infl_acc = sigm.forward(infl_acc_lt)\n","        infl_rna = sigm.forward(infl_rna_lt)\n","        \n","        mm_acc = tf.math.multiply( m_acc_lt,tf.ones([N_genes,N_cells]))\n","        mm_exp = tf.math.multiply( m_exp_lt,tf.ones([N_genes,N_cells]))\n","        ss_acc = tf.math.multiply( s_acc   ,tf.ones([N_genes,N_cells]))\n","        ss_exp = tf.math.multiply( s_exp   ,tf.ones([N_genes,N_cells]))\n","        ccor =   tf.math.multiply( cor     ,tf.ones([N_genes,N_cells]))\n","        p_acc =  tf.math.multiply( infl_acc,tf.ones([N_genes,N_cells]))\n","        p_rna =  tf.math.multiply( infl_rna,tf.ones([N_genes,N_cells]))  \n","\n","        nrm_acc = log.forward(Nrm_acc)\n","        nrm_rna = log.forward(Nrm_rna)#tf.math.multiply( ,tf.ones([N_genes,1]))\n","\n","        x_acc = yield tfd.Normal(loc = mm_acc, scale = ss_acc,name=\"x_acc\")\n","        m_cnd_exp = mm_exp+tf.math.multiply(tf.math.divide(tf.math.multiply(ss_exp,x_acc-mm_acc),ss_acc),ccor)\n","        s_cnd_exp = tf.math.sqrt(tf.math.multiply(1-tf.math.square(ccor),tf.math.square(ss_exp)))\n","\n","        x_exp = yield tfd.Normal(loc = m_cnd_exp, scale = s_cnd_exp,name=\"x_exp\")\n","\n","        pp_acc = tf.stack([p_acc,1-p_acc],axis=-1)\n","        x_acc_lt = tf.stack([-20*tf.ones_like(x_acc),x_acc+nrm_acc],axis=-1)\n","\n","        pp_rna = tf.stack([p_rna,1-p_rna],axis=-1)\n","        x_exp_lt = tf.stack([-20*tf.ones_like(x_exp),x_exp+nrm_rna],axis=-1)\n","\n","        y_acc = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_acc),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_acc_lt),\n","                                                          name=\"y_acc\")\n","        y_exp = yield tfd.MixtureSameFamily(\n","                                                          mixture_distribution = tfd.Categorical(probs=pp_rna),\n","                                                          components_distribution = tfd.Poisson(log_rate=x_exp_lt),\n","                                                          name=\"y_exp\")\n","\n","    comp_var_coroutine = tfd.JointDistributionCoroutineAutoBatched(model)\n","    return comp_var_coroutine"],"metadata":{"id":"EX3ihfd_2bhd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Use NUTS to sample from the model conditioned on observations.\n","\n","#Inference\n","@tf.function(autograph=False, jit_compile=True) \n","def sample_nuts(model,acc,exp):\n","\n","      unconstrained_bijectors = [tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity(),tfb.Identity()]\n","\n","      init = model.sample()\n","      vrr = [init[0],init[1],init[2],init[3],init[4],init[5],init[6],init[7],init[8]]\n","\n","      init_x = vrr\n","      num_burnin_iter = 3000\n","      num_warmup_iter = int(0.8*num_burnin_iter)\n","      num_chain_iter = 2000\n","\n","      target_accept_rate =0.651\n","\n","      log_post = lambda x0,x1,x2,x3,x4,x5,x6,x7,x8: model.log_prob(x0,x1,x2,x3,x4,x5,x6,x7,x8,acc,exp)\n","\n","      def trace_fn(_, pkr):\n","            return (\n","                pkr.inner_results.inner_results.target_log_prob,\n","                pkr.inner_results.inner_results.leapfrogs_taken,\n","                pkr.inner_results.inner_results.has_divergence,\n","                pkr.inner_results.inner_results.energy,\n","                pkr.inner_results.inner_results.log_accept_ratio,\n","                pkr.inner_results.inner_results.step_size\n","                  )\n","      nuts=tfp.mcmc.NoUTurnSampler(\n","                                target_log_prob_fn=log_post,\n","                                step_size=0.05,\n","                                max_tree_depth=6\n","                                    )\n","      ttk = tfp.mcmc.TransformedTransitionKernel(\n","                                inner_kernel=nuts,\n","                                bijector=unconstrained_bijectors\n","                                                    )\n","      \n","      adapted_kernel=tfp.mcmc.DualAveragingStepSizeAdaptation(\n","                                          inner_kernel=ttk,\n","                                          num_adaptation_steps=num_warmup_iter,\n","                                          target_accept_prob= target_accept_rate)\n","      \n","      states , sampler_stat =tfp.mcmc.sample_chain(\n","                        num_results=num_chain_iter,\n","                        num_burnin_steps=num_burnin_iter,\n","                        current_state=init_x,\n","                        kernel=adapted_kernel,\n","                        trace_fn=trace_fn)\n","      return states, sampler_stat"],"metadata":{"id":"zFHnE3Sa3QPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jj = 0\n","prt = 1\n","while prt < prts+1:\n","\n","                #Define hyper-parameters like number of genes and cells. Since we do not have raw coverage data and cell specific normalization constants, we generate them.\n","                x_genes = tf.constant(tf.cast(a1/prts, dtype=tf.int32),dtype=tf.int32) \n","                x_cells = tf.constant(a2,dtype=tf.int32) \n","\n","                #######################################################################################################\n","                #In case of real data Norm_acc and Norm_exp should be replaced with the relevant chunk of data.       #\n","                Norm_acc = tf.random.uniform(shape=(1,x_cells),minval=0.5,maxval=1.5,dtype=tf.float32)                #\n","                Norm_exp = tf.random.uniform(shape=(1,x_cells),minval=0.5,maxval=1.5,dtype=tf.float32)                #\n","                #######################################################################################################\n","\n","                mdl_tr = SCRaPL(x_genes,x_cells,Norm_acc,Norm_exp)\n","\n","                #########################################################################################################################################\n","                #Sample data from the generative model. If expression (yy_exp) and methylation (yy_met) readings are available this step can be ommited.#\n","                cor,mm_acc,mm_exp,ss_acc,ss_exp,infl_acc,infl_exp,xx_acc,xx_exp,yy_acc,yy_exp = mdl_tr.sample()                                         #\n","                #########################################################################################################################################\n","\n","                start = timer()\n","                samples, sampler_stat =  sample_nuts(mdl_tr,yy_acc,yy_exp)\n","                end = timer()\n","                ttime = end-start\n","\n","                #Estimate acceptance probability and step size.\n","                p_accept = tf.math.exp(tfp.math.reduce_logmeanexp(tf.minimum(sampler_stat[4], 0.)))\n","                stp_sz = sampler_stat[5][0]\n","                hmc_cor,hmc_m_acc,hmc_m_exp,hmc_s_acc,hmc_s_exp,hmc_inf_acc,hmc_inf_exp,hmc_x_acc,hmc_x_exp = samples\n","\n","                crr_nuts = tf.squeeze(hmc_cor)\n","                m_acc_nuts = tf.squeeze(hmc_m_acc)\n","                m_exp_nuts = tf.squeeze(hmc_m_exp)\n","                s_acc_nuts = tf.squeeze(hmc_s_acc)\n","                s_exp_nuts = tf.squeeze(hmc_s_exp)\n","                infl_acc_nuts  = tf.squeeze(hmc_inf_acc)\n","                infl_exp_nuts  = tf.squeeze(hmc_inf_exp)\n","                x_acc_nuts = tf.squeeze(hmc_x_acc)\n","                x_exp_nuts = tf.squeeze(hmc_x_exp)\n","\n","                qc_acc_rt = tf.math.logical_and(p_accept<0.9,p_accept>0.4)\n","                qc_stp_sz = stp_sz>0.00001\n","\n","\n","                #Save generating parameters and posterior samples.\n","\n","                if tf.math.logical_and(qc_acc_rt,qc_stp_sz)== True:\n","                      with open(Folder+'Demo/Results/nuts_cor_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(crr_nuts, handle)\n","\n","                      with open(Folder+'Demo/Results/nuts_m_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(m_acc_nuts, handle)\n","                      with open(Folder+'Demo/Results/nuts_m_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(m_exp_nuts, handle)\n","\n","                      with open(Folder+'Demo/Results/nuts_s_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(s_acc_nuts, handle)\n","                      with open(Folder+'Demo/Results/nuts_s_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(s_exp_nuts, handle)\n","\n","                      with open(Folder+'Demo/Results/nuts_inf_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(infl_acc_nuts, handle)\n","                      with open(Folder+'Demo/Results/nuts_inf_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(infl_exp_nuts, handle)\n","\n","                      print(tf.squeeze([ttime,stp_sz,p_accept]),tf.math.logical_and(qc_acc_rt,qc_stp_sz))\n","\n","                      with open(Folder+'Demo/Data/cor_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(cor, handle)\n","                      with open(Folder+'Demo/Data/mm_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(mm_acc, handle)\n","                      with open(Folder+'Demo/Data/mm_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(mm_exp, handle)\n","\n","                      with open(Folder+'Demo/Data/ss_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(ss_acc, handle)\n","                      with open(Folder+'Demo/Data/ss_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(ss_exp, handle)\n","\n","                      with open(Folder+'Demo/Data/infl_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(infl_acc, handle)\n","                      with open(Folder+'Demo/Data/infl_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(infl_exp, handle)\n","                      \n","                      with open(Folder+'Demo/Data/xx_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(xx_acc, handle)\n","                      with open(Folder+'Demo/Data/xx_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(xx_exp, handle)\n","\n","                      with open(Folder+'Demo/Data/yy_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(yy_acc, handle)\n","                      with open(Folder+'Demo/Data/yy_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(yy_exp, handle)\n","\n","                      with open(Folder+'Demo/Data/Norm_acc_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(Norm_acc, handle)  \n","                      with open(Folder+'Demo/Data/Norm_exp_'+str(a1)+'_'+str(a2)+'_10X_'+str(prt)+'.pickle', 'wb') as handle:\n","                          pickle.dump(Norm_exp, handle) \n","\n","                      prt+=1\n","                      jj=0\n","                else:\n","                      #If acceptance probability or step size are outside reasonable values we retry up to three times\n","                      if jj>3.0:\n","                          prt+=1\n","                          jj=0.0\n","                      print(\"Attempt \"+str(jj+1)+\" failed for batch \"+str(prt))\n","                      print(\"Retrying...\")\n","                      jj+=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cb7N1pGG1Nfv","executionInfo":{"status":"ok","timestamp":1649171815340,"user_tz":-60,"elapsed":671961,"user":{"displayName":"Χρήστος Μανιάτης","userId":"00852017530683764808"}},"outputId":"43a4d8f3-b1c6-4859-b6d2-e512808aad84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","tf.Tensor([3.3146463e+02 1.4890161e-03 7.3972487e-01], shape=(3,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n","tf.Tensor([3.3832516e+02 2.4875011e-03 6.2752193e-01], shape=(3,), dtype=float32) tf.Tensor(True, shape=(), dtype=bool)\n"]}]}]}